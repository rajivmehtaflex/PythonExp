{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gajraj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mindsdb loguru tictoc\n",
    "# !pip install git+https://github.com/neuml/txtai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightwood ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fdf.py\n",
    "\n",
    "\"\"\"\n",
    "2021.07.16\n",
    "\n",
    "For encoders that already fine-tune on the targets (namely text)\n",
    "the unity mixer just arg-maxes the output of the encoder.\n",
    "\"\"\"\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from lightwood.helpers.log import log\n",
    "from lightwood.mixer.base import BaseMixer\n",
    "from lightwood.encoder.base import BaseEncoder\n",
    "from lightwood.data.encoded_ds import EncodedDs\n",
    "from lightwood.api.types import PredictionArguments\n",
    "\n",
    "import asyncio\n",
    "from ttictoc import tic,toc\n",
    "from txtai.pipeline import Labels\n",
    "\n",
    "\n",
    "class FetchDB(BaseMixer):\n",
    "    def __init__(self, stop_after: float, target_encoder: BaseEncoder):\n",
    "        super().__init__(stop_after)\n",
    "        self.target_encoder = target_encoder\n",
    "        self.supports_proba = False\n",
    "        self.stable = True\n",
    "        self.labels = Labels()\n",
    "\n",
    "    def fit(self, train_data: EncodedDs, dev_data: EncodedDs) -> None:\n",
    "        tic()\n",
    "        log.info(\"Unit Mixer just borrows from encoder\")\n",
    "\n",
    "    def partial_fit(self, train_data: EncodedDs, dev_data: EncodedDs) -> None:\n",
    "        pass\n",
    "\n",
    "    def __call__(self, ds: EncodedDs,\n",
    "                 args: PredictionArguments = PredictionArguments()) -> pd.DataFrame:\n",
    "        if args.predict_proba:\n",
    "            # @TODO: depending on the target encoder, this might be enabled\n",
    "            log.warning('This model does not output probability estimates')\n",
    "\n",
    "        decoded_predictions: List[object] = []\n",
    "        # ConcatedEncodedDs([train_data, dev_data]).get_column_original_data(\"reviewtext\")\n",
    "        # tags = [\"Baseball\", \"Football\", \"Hockey\", \"Basketball\"]\n",
    "        for X, _ in ds:\n",
    "            decoded_prediction = self.target_encoder.decode(torch.unsqueeze(X, 0))\n",
    "            decoded_predictions.extend(decoded_prediction)\n",
    "\n",
    "        ydf = pd.DataFrame({\"prediction\": decoded_predictions})\n",
    "        \n",
    "        timeinfo=toc()\n",
    "        print(f'{gdb} --{timeinfo}')\n",
    "        return ydf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/workspace/PythonExp/lightwoodexp/airline.csv')\n",
    "# df=df[['airline_sentiment','text']]\n",
    "# df=df.rename(columns={\"airline_sentiment\":\"sentiment\"})\n",
    "df=df.iloc[:100]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"airline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import ProblemDefinition, json_ai_from_problem, load_custom_module\n",
    "import pandas as pd\n",
    "\n",
    "# load the code\n",
    "load_custom_module('./fdf.py')\n",
    "\n",
    "# read dataset\n",
    "df = pd.read_csv('/workspace/PythonExp/lightwoodexp/airline.csv')\n",
    "\n",
    "# define the predictive task\n",
    "pdef = ProblemDefinition.from_dict({\n",
    "    'target': 'sentiment', # column you want to predict\n",
    "})\n",
    "\n",
    "# generate the Json AI intermediate representation from the data and its corresponding settings\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "\n",
    "# Print it (you can also put it in a file and edit it there)\n",
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_ai.model['args']['submodels'] = [\n",
    "                {\n",
    "                    \"module\": \"fdf.FetchDB\",\n",
    "                    \"args\": {\n",
    "                        \"target_encoder\": \"$encoders[self.target]\",\n",
    "                        \"stop_after\": \"$problem_definition.seconds_per_mixer\"\n",
    "                    }\n",
    "                }\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import code_from_json_ai, predictor_from_code\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)\n",
    "predictor.learn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(pd.DataFrame({\n",
    "    'text': ['you are beautyful','are you mad?','Where are you bloodyful']\n",
    "}))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AsyncOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile asyncexp.py\n",
    "import asyncio\n",
    "from ttictoc import tic,toc\n",
    "result=None\n",
    "tic()\n",
    "async def foo(msg):\n",
    "    print('Hello')\n",
    "    await asyncio.sleep(.01)\n",
    "    print(msg)\n",
    "    return msg\n",
    "    \n",
    "async def manager():\n",
    "    tasklist=[]\n",
    "    for i in range(400):\n",
    "        task=asyncio.create_task(foo(str(i)))\n",
    "        tasklist.append(task)\n",
    "    \n",
    "    data=asyncio.gather(*tasklist)\n",
    "    print('Result::')\n",
    "    result=await data\n",
    "    print('Done')\n",
    "    return result\n",
    "    \n",
    "\n",
    "\n",
    "gdb=asyncio.run(manager())\n",
    "timeinfo=toc()\n",
    "print(f'{gdb} --{timeinfo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python asyncexp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile asyncexp.py\n",
    "\n",
    "import asyncio\n",
    "from ttictoc import tic,toc\n",
    "from txtai.pipeline import Labels\n",
    "\n",
    "labels = Labels()\n",
    "result=None\n",
    "\n",
    "\n",
    "tic()\n",
    "\n",
    "async def foo(text,tags):\n",
    "    print(text)\n",
    "    await asyncio.sleep(.001)\n",
    "    result=tags[labels(text, tags)[0][0]]\n",
    "    print(result)\n",
    "    return result\n",
    "    \n",
    "async def manager():\n",
    "    tasklist=[]\n",
    "    \n",
    "    data = [\"Dodgers lose again, give up 3 HRs in a loss to the Giants\",\n",
    "            \"Giants 5 Cardinals 4 final in extra innings\",\n",
    "            \"Dodgers drop Game 2 against the Giants, 5-4\",\n",
    "            \"Flyers 4 Lightning 1 final. 45 saves for the Lightning.\",\n",
    "            \"Slashing, penalty, 2 minute power play coming up\",\n",
    "            \"What a stick save!\",\n",
    "            \"Leads the NFL in sacks with 9.5\",\n",
    "            \"UCF 38 Temple 13\",\n",
    "            \"With the 30 yard completion, down to the 10 yard line\",\n",
    "            \"Drains the 3pt shot!!, 0:15 remaining in the game\",\n",
    "            \"Intercepted! Drives down the court and shoots for the win\",\n",
    "            \"Massive dunk!!! they are now up by 15 with 2 minutes to go\"]\n",
    "\n",
    "    tags = [\"Baseball\", \"Football\", \"Hockey\", \"Basketball\"]\n",
    "    \n",
    "    \n",
    "    for i in data:\n",
    "        task=asyncio.create_task(foo(str(i),tags))\n",
    "        tasklist.append(task)\n",
    "    \n",
    "    data=asyncio.gather(*tasklist)\n",
    "    print('Result::')\n",
    "    result=await data\n",
    "    print('Done')\n",
    "    return result\n",
    "    \n",
    "\n",
    "\n",
    "gdb=asyncio.run(manager())\n",
    "timeinfo=toc()\n",
    "print(f'{gdb} --{timeinfo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from math import sqrt\n",
    "from ttictoc import tic,toc\n",
    "from txtai.pipeline import Labels\n",
    "\n",
    "labels = Labels()\n",
    "\n",
    "data = [\"Dodgers lose again, give up 3 HRs in a loss to the Giants\",\n",
    "        \"Giants 5 Cardinals 4 final in extra innings\",\n",
    "        \"Dodgers drop Game 2 against the Giants, 5-4\",\n",
    "        \"Flyers 4 Lightning 1 final. 45 saves for the Lightning.\",\n",
    "        \"Slashing, penalty, 2 minute power play coming up\",\n",
    "        \"What a stick save!\",\n",
    "        \"Leads the NFL in sacks with 9.5\",\n",
    "        \"UCF 38 Temple 13\",\n",
    "        \"With the 30 yard completion, down to the 10 yard line\",\n",
    "        \"Drains the 3pt shot!!, 0:15 remaining in the game\",\n",
    "        \"Intercepted! Drives down the court and shoots for the win\",\n",
    "        \"Massive dunk!!! they are now up by 15 with 2 minutes to go\"]\n",
    "\n",
    "tags = [\"Baseball\", \"Football\", \"Hockey\", \"Basketball\"]\n",
    "\n",
    "\n",
    "def foo(text,tags):\n",
    "    print(text)\n",
    "    result=tags[labels(text, tags)[0][0]]\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "tic()\n",
    "# data=Parallel(n_jobs=10)(delayed(sqrt)(i**2) for i in range(1000))\n",
    "data=Parallel(n_jobs=10)(delayed(foo)(i,tags) for i in data)\n",
    "timeinfo=toc()\n",
    "print(f'timeinfo --{timeinfo} --{data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # async def _foo(text,tags):\n",
    "    #     print(text)\n",
    "    #     await asyncio.sleep(.001)\n",
    "    #     result=tags[labels(text, tags)[0][0]]\n",
    "    #     print(result)\n",
    "    #     return result\n",
    "\n",
    "\n",
    "    # async def _manager():\n",
    "    #     tasklist=[]\n",
    "        \n",
    "    #     data = [\"Dodgers lose again, give up 3 HRs in a loss to the Giants\",\n",
    "    #             \"Giants 5 Cardinals 4 final in extra innings\",\n",
    "    #             \"Dodgers drop Game 2 against the Giants, 5-4\",\n",
    "    #             \"Flyers 4 Lightning 1 final. 45 saves for the Lightning.\",\n",
    "    #             \"Slashing, penalty, 2 minute power play coming up\",\n",
    "    #             \"What a stick save!\",\n",
    "    #             \"Leads the NFL in sacks with 9.5\",\n",
    "    #             \"UCF 38 Temple 13\",\n",
    "    #             \"With the 30 yard completion, down to the 10 yard line\",\n",
    "    #             \"Drains the 3pt shot!!, 0:15 remaining in the game\",\n",
    "    #             \"Intercepted! Drives down the court and shoots for the win\",\n",
    "    #             \"Massive dunk!!! they are now up by 15 with 2 minutes to go\"]\n",
    "\n",
    "    #     tags = [\"Baseball\", \"Football\", \"Hockey\", \"Basketball\"]\n",
    "        \n",
    "        \n",
    "    #     for i in data:\n",
    "    #         task=asyncio.create_task(foo(str(i),tags))\n",
    "    #         tasklist.append(task)\n",
    "        \n",
    "    #     data=asyncio.gather(*tasklist)\n",
    "    #     print('Result::')\n",
    "    #     result=await data\n",
    "    #     print('Done')\n",
    "    #     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rasaexp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2db985dd0df9d99b829f2f174e65e3f723330059c6554b59c316a992f814138"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
