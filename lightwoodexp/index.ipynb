{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gajraj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install mindsdb\n",
    "# !conda list\n",
    "#Following command should run on terminal and wait for some time to up and run\n",
    "#!python -m mindsdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register extended component (e.g Mixer,Encoder,Functionality etc..) via different code (Registration proceess i.e refer in lightwood tutorial).\n",
    "\n",
    "#### Consume with mindsdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightwood.api.high_level import (\n",
    "    ProblemDefinition,\n",
    "    json_ai_from_problem,\n",
    "    code_from_json_ai,\n",
    "    predictor_from_code,\n",
    ")\n",
    "\n",
    "# Load a pandas dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/hdi/data.csv\"\n",
    ")\n",
    "\n",
    "# Define the prediction task by naming the target column\n",
    "pdef = ProblemDefinition.from_dict(\n",
    "    {\n",
    "        \"target\": \"Development Index\",  # column you want to predict\n",
    "    }\n",
    ")\n",
    "\n",
    "# Generate JSON-AI code to model the problem\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightwood.api.high_level import (\n",
    "    ProblemDefinition,\n",
    "    json_ai_from_problem,\n",
    "    code_from_json_ai,\n",
    "    predictor_from_code,\n",
    ")\n",
    "\n",
    "# Load a pandas dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/hdi/data.csv\"\n",
    ")\n",
    "\n",
    "# Define the prediction task by naming the target column\n",
    "pdef = ProblemDefinition.from_dict(\n",
    "    {\n",
    "        \"target\": \"Development Index\",  # column you want to predict\n",
    "    }\n",
    ")\n",
    "\n",
    "# Generate JSON-AI code to model the problem\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "\n",
    "# OPTIONAL - see the JSON-AI syntax\n",
    "#print(json_ai.to_json())\n",
    "\n",
    "# Generate python code\n",
    "code = code_from_json_ai(json_ai)\n",
    "\n",
    "# OPTIONAL - see generated code\n",
    "#print(code)\n",
    "\n",
    "# Create a predictor from python code\n",
    "predictor = predictor_from_code(code)\n",
    "\n",
    "# Train a model end-to-end from raw data to a finalized predictor\n",
    "predictor.learn(df)\n",
    "\n",
    "# Make the train/test splits and show predictions for a few examples\n",
    "test_df = predictor.split(predictor.preprocess(df))[\"test\"]\n",
    "preds = predictor.predict(test_df).iloc[:10]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_ai.model['args']['submodels'] = [{\n",
    "    'module': 'random_forest_mixer.RandomForestMixer',\n",
    "    'args': {\n",
    "        'stop_after': '$problem_definition.seconds_per_mixer',\n",
    "        'dtype_dict': '$dtype_dict',\n",
    "        'target': '$target',\n",
    "                'target_encoder': '$encoders[self.target]'\n",
    "\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import code_from_json_ai, predictor_from_code\n",
    "\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)\n",
    "predictor.learn(df)\n",
    "predictions = predictor.predict(pd.DataFrame({\n",
    "    'age': [63, 15, None],\n",
    "    'sex': [1, 1, 0],\n",
    "    'thal': [3, 1, 1]\n",
    "}))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated extended models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile faker.py\n",
    "\n",
    "from lightwood.mixer import BaseMixer\n",
    "from lightwood.api.types import PredictionArguments\n",
    "from lightwood.data.encoded_ds import EncodedDs, ConcatedEncodedDs\n",
    "from lightwood import dtype\n",
    "from lightwood.encoder import BaseEncoder\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "\n",
    "class Faker(BaseMixer):\n",
    "\n",
    "    def __init__(self, stop_after: int, dtype_dict: dict, target: str, target_encoder: BaseEncoder):\n",
    "        super().__init__(stop_after)\n",
    "        self.target_encoder = target_encoder\n",
    "        # Throw in case someone tries to use this for a problem that's not classification, I'd fail anyway, but this way the error message is more intuitive\n",
    "        if dtype_dict[target] not in (dtype.categorical, dtype.binary):\n",
    "            raise Exception(f'This mixer can only be used for classification problems! Got target dtype {dtype_dict[target]} instead!')\n",
    "\n",
    "        # We could also initialize this in `fit` if some of the parameters depend on the input data, since `fit` is called exactly once\n",
    "        logger.add(\"/home/gitpod/out.log\")\n",
    "        logger.info(\"If you're using Python {}, prefer {feature} of course!\",sys.version , feature=\"f-strings\")\n",
    "\n",
    "    def fit(self, train_data: EncodedDs, dev_data: EncodedDs) -> None:\n",
    "        # By default mixers get some train data and a bit of dev data on which to do early stopping or hyper parameter optimization. For this mixer, we don't need dev data, so we're going to concat the two in order to get more training data. Then, we're going to turn them into an sklearn friendly foramat.\n",
    "        logger.info(f'train_data --> {train_data}')\n",
    "        ...\n",
    "        \n",
    "    def __call__(self, ds: EncodedDs, args: PredictionArguments = PredictionArguments()) -> pd.DataFrame:\n",
    "        # Turn the data into an sklearn friendly format\n",
    "\n",
    "        # Finally, turn the decoded predictions into a dataframe with a single column called `prediction`. This is the standard behaviour all lightwood mixers use\n",
    "        ydf = pd.DataFrame({'prediction': list(range(1000))})\n",
    "        logger.info(f'while prediction --> {ydf}')\n",
    "        return ydf\n",
    "\n",
    "    \n",
    "    # We'll skip implementing `partial_fit`, thus making this mixer unsuitable for online training tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import ProblemDefinition, json_ai_from_problem, load_custom_module\n",
    "import pandas as pd\n",
    "\n",
    "# load the code\n",
    "load_custom_module('./faker.py')\n",
    "\n",
    "# read dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/heart_disease/data.csv')\n",
    "\n",
    "# define the predictive task\n",
    "pdef = ProblemDefinition.from_dict({\n",
    "    'target': 'target', # column you want to predict\n",
    "})\n",
    "\n",
    "# generate the Json AI intermediate representation from the data and its corresponding settings\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "\n",
    "# Print it (you can also put it in a file and edit it there)\n",
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_ai.model['args']['submodels'] = [{\n",
    "    'module': 'faker.Faker',\n",
    "    'args': {\n",
    "        'stop_after': '$problem_definition.seconds_per_mixer',\n",
    "        'dtype_dict': '$dtype_dict',\n",
    "        'target': '$target',\n",
    "        'target_encoder': '$encoders[self.target]'\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import code_from_json_ai, predictor_from_code\n",
    "\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)\n",
    "predictor.learn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('uiexp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e401a5a0a82dd3f6793fe48247ce39efc51ddc7576ea94bee0589417d4c87d49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
