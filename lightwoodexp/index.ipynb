{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gajraj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install mindsdb\n",
    "# !conda list\n",
    "#Following command should run on terminal and wait for some time to up and run\n",
    "#!python -m mindsdb\n",
    "# !pip install mindsdb\n",
    "# !pip install loguru \n",
    "# !pip install pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register extended component (e.g Mixer,Encoder,Functionality etc..) via different code (Registration proceess i.e refer in lightwood tutorial).\n",
    "\n",
    "#### Consume with mindsdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightwood.api.high_level import (\n",
    "    ProblemDefinition,\n",
    "    json_ai_from_problem,\n",
    "    code_from_json_ai,\n",
    "    predictor_from_code,\n",
    ")\n",
    "\n",
    "# Load a pandas dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/hdi/data.csv\"\n",
    ")\n",
    "\n",
    "# Define the prediction task by naming the target column\n",
    "pdef = ProblemDefinition.from_dict(\n",
    "    {\n",
    "        \"target\": \"Development Index\",  # column you want to predict\n",
    "    }\n",
    ")\n",
    "\n",
    "# Generate JSON-AI code to model the problem\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightwood.api.high_level import (\n",
    "    ProblemDefinition,\n",
    "    json_ai_from_problem,\n",
    "    code_from_json_ai,\n",
    "    predictor_from_code,\n",
    ")\n",
    "\n",
    "# Load a pandas dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/hdi/data.csv\"\n",
    ")\n",
    "\n",
    "# Define the prediction task by naming the target column\n",
    "pdef = ProblemDefinition.from_dict(\n",
    "    {\n",
    "        \"target\": \"Development Index\",  # column you want to predict\n",
    "    }\n",
    ")\n",
    "\n",
    "# Generate JSON-AI code to model the problem\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "\n",
    "# OPTIONAL - see the JSON-AI syntax\n",
    "#print(json_ai.to_json())\n",
    "\n",
    "# Generate python code\n",
    "code = code_from_json_ai(json_ai)\n",
    "\n",
    "# OPTIONAL - see generated code\n",
    "#print(code)\n",
    "\n",
    "# Create a predictor from python code\n",
    "predictor = predictor_from_code(code)\n",
    "\n",
    "# Train a model end-to-end from raw data to a finalized predictor\n",
    "predictor.learn(df)\n",
    "\n",
    "# Make the train/test splits and show predictions for a few examples\n",
    "test_df = predictor.split(predictor.preprocess(df))[\"test\"]\n",
    "preds = predictor.predict(test_df).iloc[:10]\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_ai.model['args']['submodels'] = [{\n",
    "    'module': 'random_forest_mixer.RandomForestMixer',\n",
    "    'args': {\n",
    "        'stop_after': '$problem_definition.seconds_per_mixer',\n",
    "        'dtype_dict': '$dtype_dict',\n",
    "        'target': '$target',\n",
    "                'target_encoder': '$encoders[self.target]'\n",
    "\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import code_from_json_ai, predictor_from_code\n",
    "\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)\n",
    "predictor.learn(df)\n",
    "predictions = predictor.predict(pd.DataFrame({\n",
    "    'age': [63, 15, None],\n",
    "    'sex': [1, 1, 0],\n",
    "    'thal': [3, 1, 1]\n",
    "}))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated extended models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./amazon.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile faker.py\n",
    "\n",
    "\n",
    "from lightwood.mixer import BaseMixer\n",
    "from lightwood.api.types import PredictionArguments\n",
    "from lightwood.data.encoded_ds import EncodedDs, ConcatedEncodedDs\n",
    "from lightwood import dtype\n",
    "from lightwood.encoder import BaseEncoder\n",
    "from loguru import logger\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "\n",
    "class Faker(BaseMixer):\n",
    "    # clf: RandomForestClassifier\n",
    "\n",
    "    def __init__(self, stop_after: int, dtype_dict: dict, target: str, target_encoder: BaseEncoder):\n",
    "        super().__init__(stop_after)\n",
    "        self.target_encoder = target_encoder\n",
    "        self.stable=True\n",
    "        # Throw in case someone tries to use this for a problem that's not classification, I'd fail anyway, but this way the error message is more intuitive\n",
    "        if dtype_dict[target] not in (dtype.categorical, dtype.binary):\n",
    "            raise Exception(f'This mixer can only be used for classification problems! Got target dtype {dtype_dict[target]} instead!')\n",
    "\n",
    "        # We could also initialize this in `fit` if some of the parameters depend on the input data, since `fit` is called exactly once\n",
    "        # self.clf = RandomForestClassifier(max_depth=30)\n",
    "        logger.add(\"/home/gitpod/out.log\")\n",
    "        self.sentiment_pipeline = pipeline(\"sentiment-analysis\") \n",
    "        # logger.info(\"If you're using Python {}, prefer {feature} of course!\",sys.version , feature=\"f-strings\")\n",
    "\n",
    "    def fit(self, train_data: EncodedDs, dev_data: EncodedDs) -> None:\n",
    "        X, Y = [], []\n",
    "        # By default mixers get some train data and a bit of dev data on which to do early stopping or hyper parameter optimization. For this mixer, we don't need dev data, so we're going to concat the two in order to get more training data. Then, we're going to turn them into an sklearn friendly foramat.\n",
    "        logger.info(f'original data --> {ConcatedEncodedDs([train_data, dev_data]).get_column_original_data(\"reviewtext\")}')\n",
    "        for x, y in ConcatedEncodedDs([train_data, dev_data]):\n",
    "            # logger.info(f'converted_train_data --> {x.tolist()}')\n",
    "            X.append(x.tolist())\n",
    "            Y.append(y.tolist())\n",
    "            \n",
    "        # self.clf.fit(X, Y)\n",
    "        \n",
    "\n",
    "    def __call__(self, ds: EncodedDs,\n",
    "                 args: PredictionArguments = PredictionArguments()) -> pd.DataFrame:\n",
    "        # Turn the data into an sklearn friendly format\n",
    "        X = []\n",
    "        # for x, _ in ds:\n",
    "        #     # logger.info(f'while prediction process--> {x.tolist()}')\n",
    "        #     X.append(x.tolist())\n",
    "\n",
    "        # Yh = self.clf.predict(X)\n",
    "        for item in ConcatedEncodedDs([ds]).get_column_original_data(\"reviewtext\").tolist():       \n",
    "            logger.info(f'original data for prediction--> {item}')\n",
    "            X.append((1 if self.sentiment_pipeline([item])[0]['label'] == 'POSITIVE' else 0))            \n",
    "        # # Lightwood encoders are meant to decode torch tensors, so we have to cast the predictions first\n",
    "        # decoded_predictions = self.target_encoder.decode(torch.Tensor(Yh))\n",
    "\n",
    "        # Finally, turn the decoded predictions into a dataframe with a single column called `prediction`. This is the standard behaviour all lightwood mixers use\n",
    "        \n",
    "        # logger.info(f'decoded prediction --> {decoded_predictions} , {type(decoded_predictions)}')\n",
    "        # decoded_predictions=[str(i) for i in range(len(ds))]\n",
    "        decoded_predictions=[str(i) for i in X]\n",
    "        logger.info(f'decoded prediction --> {decoded_predictions} , {type(decoded_predictions)}')\n",
    "        ydf = pd.DataFrame({'prediction': decoded_predictions})\n",
    "        return ydf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import ProblemDefinition, json_ai_from_problem, load_custom_module\n",
    "import pandas as pd\n",
    "\n",
    "# load the code\n",
    "load_custom_module('./faker.py')\n",
    "\n",
    "# read dataset\n",
    "# df = pd.read_csv('https://raw.githubusercontent.com/mindsdb/benchmarks/main/benchmarks/datasets/heart_disease/data.csv')\n",
    "\n",
    "# define the predictive task\n",
    "pdef = ProblemDefinition.from_dict({\n",
    "    'target': 'positive', # column you want to predict\n",
    "})\n",
    "\n",
    "# generate the Json AI intermediate representation from the data and its corresponding settings\n",
    "json_ai = json_ai_from_problem(df, problem_definition=pdef)\n",
    "\n",
    "# Print it (you can also put it in a file and edit it there)\n",
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_ai.model['args']['submodels'] = [{\n",
    "    'module': 'faker.Faker',\n",
    "    'args': {\n",
    "        'stop_after': '$problem_definition.seconds_per_mixer',\n",
    "        'dtype_dict': '$dtype_dict',\n",
    "        'target': '$target',\n",
    "        'target_encoder': '$encoders[self.target]'\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = code_from_json_ai(json_ai)\n",
    "\n",
    "print(code)\n",
    "\n",
    "# Save code to a file (Optional)\n",
    "with open('sample.py', 'w') as fp:\n",
    "    fp.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json_ai.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightwood.api.high_level import code_from_json_ai, predictor_from_code\n",
    "code = code_from_json_ai(json_ai)\n",
    "predictor = predictor_from_code(code)\n",
    "predictor.learn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(pd.DataFrame({\n",
    "    'reviewtext': ['What the hell','are you mad?','Where are you bloodyful']\n",
    "}))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"This is a pretty good version of the game for being free. There are LOTS of different levels to play. My kids enjoy it a lot too.\"]\n",
    "data = [data[0].split(\".\")[0]]\n",
    "data=(1 if sentiment_pipeline(data)[0]['label'] == 'POSITIVE' else 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reviewtext=df.reviewtext.apply(lambda x : x.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"amazon.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('uiexp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e401a5a0a82dd3f6793fe48247ce39efc51ddc7576ea94bee0589417d4c87d49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
